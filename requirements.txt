# Core dependencies
torch>=2.8
numpy>=1.24.0
transformers>=4.35.0

# Distributed training
deepspeed>=0.12.0
megatron-core>=0.4.0

# DeepSeek components (install from source)
# FlashMLA: https://github.com/deepseek-ai/FlashMLA
# DeepEP: https://github.com/deepseek-ai/DeepEP

# Flash Attention (required for FlashMLA)
flash-attn>=2.3.0

# Data processing
datasets>=2.14.0
tokenizers>=0.15.0
pyarrow>=14.0.0          # For Parquet format support
ftfy>=6.1.0              # Fix text encoding issues (preliminary cleaning)
datasketch>=1.6.5        # MinHash LSH for deduplication (Lee et al. 2022)
langdetect>=1.0.9        # Language detection
fasttext-wheel>=0.9.2    # Quality classification (Xu et al. 2024)
regex>=2023.10.0         # Advanced regex for text processing
zstandard>=0.21.0        # Compression support for datasets
arxiv>=2.0.0             # For downloading citation PDFs (pdf_citations/download_papers.py)

# GPU-accelerated deduplication (FED - Son et al. 2025)
# 107× speedup with GPU acceleration
cupy-cuda12x>=13.6.0     # CUDA arrays and kernels for FED (CUDA 12.x compatible)
fastrlock>=0.8.3         # Fast RLock implementation (CuPy dependency)
# faiss-gpu>=1.12.0      # FAISS with GPU support - built from source on Windows
                         # NOTE: Install from https://github.com/myuanz/faiss following Windows build instructions
                         # Requires: Visual Studio 2022, CUDA 12.9, CMake, Ninja, SWIG, OpenBLAS

# Memory-efficient deduplication (LSHBloom - Khan et al. 2024)
pybloom-live>=4.0.0      # Bloom filters for LSHBloom (10× memory reduction)

# Monitoring and logging
wandb>=0.16.0
tensorboard>=2.15.0

# Utilities
pyyaml>=6.0
tqdm>=4.66.0
packaging>=23.0
psutil>=5.9.0  # Memory profiling for pipeline tests

# Optimization
ninja>=1.11.0  # For faster compilation
triton>=2.1.0  # For custom kernels

# Optional: Debugging and profiling
py-spy>=0.3.14
nvtx>=0.2.5
