{
  "_comment": "Mapping of arXiv IDs to PDF filenames generated by download_papers.py",
  "2412.19437": "DeepSeek-AI et al. - DeepSeek-V3 Technical Report.pdf",
  "2203.15556": "Jordan Hoffmann et al. - Training Compute-Optimal Large Language Models.pdf",
  "2402.00159": "Luca Soldaini et al. - Dolma_ an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research.pdf",
  "2107.06499": "Katherine Lee et al. - Deduplicating Training Data Makes Language Models Better.pdf",
  "2505.18458": "Xuanhe Zhou et al. - A Survey of LLM $_times$ DATA.pdf",
  "2501.01046": "Youngjun Son et al. - FED_ Fast and Efficient Dataset Deduplication Framework with GPU Acceleration.pdf",
  "2411.04257": "Arham Khan et al. - LSHBloom_ Memory-efficient, Extreme-scale Document Deduplication.pdf",
  "2409.09613": "Yungi Kim et al. - Rethinking KenLM_ Good and Bad Model Ensembles for Efficient Text Quality Filtering in Large Web Corpora.pdf",
  "2510.00866": "Thiziri Nait Saada et al. - The Data-Quality Illusion_ Rethinking Classifier-Based Quality Filtering for LLM Pretraining.pdf",
  "2406.11794": "Jeffrey Li et al. - DataComp-LM_ In search of the next generation of training sets for language models.pdf",
  "2406.17557": "Guilherme Penedo et al. - The FineWeb Datasets_ Decanting the Web for the Finest Text Data at Scale.pdf",
  "2306.01116": "Guilherme Penedo et al. - The RefinedWeb Dataset for Falcon LLM_ Outperforming Curated Corpora with Web Data, and Web Data Only.pdf",
  "2305.10429": "Sang Michael Xie et al. - DoReMi_ Optimizing Data Mixtures Speeds Up Language Model Pretraining.pdf",
  "2112.11446": "Jack W. Rae et al. - Scaling Language Models_ Methods, Analysis & Insights from Training Gopher.pdf",
  "2101.00027": "Leo Gao et al. - The Pile_ An 800GB Dataset of Diverse Text for Language Modeling.pdf",
  "1910.10683": "Colin Raffel et al. - Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.pdf",
  "2001.08361": "Jared Kaplan et al. - Scaling Laws for Neural Language Models.pdf",
  "1607.01759": "Armand Joulin et al. - Bag of Tricks for Efficient Text Classification.pdf"
}
